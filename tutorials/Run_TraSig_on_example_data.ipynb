{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import bottleneck as bn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run TraSig on the example data\n",
    "\n",
    "1. The inputs are prepared following the Prepare_input_from_dynverse_ti_methods.ipynb tutorial.\n",
    "2. For the following demo, we use the default multiprocessing (4 cores) setting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(input='../example/input', listType='ligand_receptor', metric='dot', modelName='ti_slingshot', multiProcess=True, nLap=20, nan2zero=True, ncores=4, numPerms='1000', output='../example/output', preprocess='None', project='oligodendrocyte-differentiation-clusters_marques', startingTreatment='smallerWindow')\n",
      "Load:  oligodendrocyte-differentiation-clusters_marques_lr.txt\n",
      "Permutations grouped to different cores: [range(1, 334), range(334, 667), range(667, 1000), range(1000, 1001)]\n",
      "CPU times: user 652 ms, sys: 115 ms, total: 767 ms\n",
      "Wall time: 39.8 s\n"
     ]
    }
   ],
   "source": [
    "%time ! main.py -i ../example/input -o ../example/output -d oligodendrocyte-differentiation-clusters_marques -g None -b ti_slingshot -n 1000 -s smallerWindow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load:  oligodendrocyte-differentiation-clusters_marques_lr.txt\n"
     ]
    }
   ],
   "source": [
    "project = \"oligodendrocyte-differentiation-clusters_marques\"\n",
    "preprocess = \"\"\n",
    "model_name = \"ti_slingshot\"\n",
    "others = \"\"\n",
    "list_type = 'ligand_receptor'\n",
    "startingTreatment = \"smallerWindow\"\n",
    "\n",
    "if preprocess != \"\":\n",
    "    _preprocess = f\"_{preprocess}\"\n",
    "else:\n",
    "    _preprocess = \"\"\n",
    "    \n",
    "if startingTreatment != \"None\":\n",
    "    _startingTreatment = f\"_{startingTreatment}\"\n",
    "else:\n",
    "    _startingTreatment = \"\"\n",
    "\n",
    "n_lap = 20 # smoothing window\n",
    "metrics = ['dot']\n",
    "nan2zero = True\n",
    "num_perms = 1e3\n",
    "\n",
    "input_path = '../example/input'\n",
    "output_path = '../example/output'\n",
    "\n",
    "suffix = f\"{project}_{list_type}{_preprocess}_{model_name}\"\n",
    "suffix = f\"{suffix}{_startingTreatment}_nlap_{n_lap}{others}\"\n",
    "child_suffix = f\"{suffix}_{metrics[0]}_{int(np.log10(num_perms))}\"\n",
    "\n",
    "\n",
    "# get interaction file (list of (ligand, receptor/target))\n",
    "filename = f\"{list_type}_{project}{_preprocess}.pickle\"\n",
    "with open(os.path.join(input_path, filename), 'rb') as handle:\n",
    "    interaction_list = pickle.load(handle)\n",
    "\n",
    "    \n",
    "# load expression data\n",
    "filename = f\"{project}{_preprocess}_lr.txt\"\n",
    "print(\"Load: \", filename)\n",
    "\n",
    "data_file = os.path.join(input_path, filename)\n",
    "df = pd.read_csv(data_file, index_col=0)\n",
    "cell_exps = df.values\n",
    "gene_names = list(df.columns.values)  # assume unique\n",
    "\n",
    "\n",
    "# (optional) load corresponding between sampling time and path\n",
    "filename = f\"sampling_time_per_path_{project}{_preprocess}_{model_name}.pickle\"\n",
    "with open(os.path.join(input_path, filename), 'rb') as handle:\n",
    "    time2path = pickle.load(handle)\n",
    "\n",
    "path2time = dict()\n",
    "for k, ps in time2path.items():\n",
    "    for p in ps:\n",
    "        path2time[p] = k\n",
    "\n",
    "        \n",
    "# load path & time assignment\n",
    "# original assignment\n",
    "hid_var_file = f\"{project}{_preprocess}_{model_name}_it2_hid_var.pickle\"\n",
    "with open(os.path.join(input_path, hid_var_file), 'rb') as handle:\n",
    "    hid_var = pickle.load(handle, encoding=\"latin1\")\n",
    "\n",
    "unique_paths = np.unique(hid_var[\"cell_path\"])\n",
    "all_times = [round(i, 2) for i in np.arange(0, 1.01, 0.01)]  # all possible labels for cell time\n",
    "cell_paths_o = hid_var[\"cell_path\"]\n",
    "cell_times_o = hid_var[\"cell_time\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the scores on the original data \n",
    "_n = 0\n",
    "\n",
    "_columns = dict.fromkeys(metrics)\n",
    "for m in metrics:\n",
    "    _columns[m] = []\n",
    "\n",
    "_columns.update({'pair': [], 'gene_pair_id': []})\n",
    "\n",
    "# load results  \n",
    "filename = f\"{suffix}_metrics_{_n}.pickle\"\n",
    "data_file = os.path.join(output_path, filename)\n",
    "\n",
    "with open(data_file, 'rb') as handle:\n",
    "    results = pickle.load(handle)\n",
    "\n",
    "for pair, mets in results.items():\n",
    "    for m in metrics:\n",
    "        _columns[m] += list(mets[m])\n",
    "\n",
    "    _columns['pair'] += list(np.repeat(pair, len(mets[m])))\n",
    "    _columns['gene_pair_id'] += list(range(len(mets[m])))\n",
    "    \n",
    "df = pd.DataFrame(_columns)\n",
    "num_pairs = len(results[pair][m])\n",
    "\n",
    "\n",
    "# load permutation results  \n",
    "filename = f\"{suffix}_permutation_results.pickle\"\n",
    "data_file = os.path.join(output_path, filename)\n",
    "\n",
    "with open(data_file, 'rb') as handle:\n",
    "    pair2counts = pickle.load(handle)\n",
    "\n",
    "    \n",
    "# turn to p-values; modified formula 4-29-21: (count + 1) / (num_perms + 1)\n",
    "for pair, _ in pair2counts.items():\n",
    "    for m in metrics:\n",
    "         pair2counts[pair][m] = (pair2counts[pair][m] + 1)/(num_perms + 1)\n",
    "\n",
    "            \n",
    "# add to the dataframe            \n",
    "_columns = dict.fromkeys(metrics)\n",
    "for m in metrics:\n",
    "    _columns[m] = []\n",
    "\n",
    "for pair, counts in pair2counts.items():\n",
    "    for m in metrics:\n",
    "        _columns[m] += list(counts[m])\n",
    "        \n",
    "for m in metrics:\n",
    "    df[f\"{m}_p\"] = _columns[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add ligand target info\n",
    "df['ligand'] = [interaction_list[int(i)][0] for i in df['gene_pair_id']]\n",
    "df['target'] = [interaction_list[int(i)][1] for i in df['gene_pair_id']]\n",
    "ligand_list = np.unique(df['ligand'])\n",
    "\n",
    "# add more info about cell clusters \n",
    "df['sender'] = [i.split('_')[0] for i in df['pair']]\n",
    "df['receiver'] = [i.split('_')[1] for i in df['pair']]\n",
    "df['sender'] = df['sender'].astype('int')\n",
    "df['receiver'] = df['receiver'].astype('int')\n",
    "df['time-sender'] = [path2time[i] for i in df['sender']]\n",
    "df['time-receiver'] = [path2time[i] for i in df['receiver']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust p-values for multiple comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add adjusted p-values \n",
    "import statsmodels.api as sm\n",
    "import statsmodels as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted P same as unadjusted? : False\n",
      "Adjusted P same as unadjusted? : False\n",
      "Adjusted P same as unadjusted? : False\n",
      "Adjusted P same as unadjusted? : False\n",
      "Adjusted P same as unadjusted? : False\n",
      "Adjusted P same as unadjusted? : False\n",
      "Adjusted P same as unadjusted? : False\n",
      "Adjusted P same as unadjusted? : False\n",
      "Adjusted P same as unadjusted? : False\n",
      "Adjusted P same as unadjusted? : False\n",
      "Adjusted P same as unadjusted? : False\n",
      "Adjusted P same as unadjusted? : False\n",
      "Adjusted P same as unadjusted? : False\n",
      "Adjusted P same as unadjusted? : False\n",
      "Adjusted P same as unadjusted? : False\n",
      "Adjusted P same as unadjusted? : False\n"
     ]
    }
   ],
   "source": [
    "p_adjusted = df['dot_p'].values.copy()\n",
    "_p = df['dot_p'].values.copy()\n",
    "\n",
    "for pair in results.keys(): \n",
    "    condition = np.where(df['pair'] == pair)[0]\n",
    "    adjusted = sm.stats.multitest.fdrcorrection(df['dot_p'].values[condition])\n",
    "    _p[condition] = adjusted[1]\n",
    "    \n",
    "    print(f\"Adjusted P same as unadjusted? : {(_p == p_adjusted).all()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dot_p_adjusted'] = _p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:testing]",
   "language": "python",
   "name": "conda-env-testing-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
